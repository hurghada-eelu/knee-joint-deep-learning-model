{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8426101,
          "sourceType": "datasetVersion",
          "datasetId": 5017261
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout,Conv2D,MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "o1A5QbT_XVgD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBztkepUwtwq",
        "outputId": "abb89e12-23c7-49a7-fcf3-7897266225b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to the datasets\n",
        "\n",
        "\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/new dataset/train\"\n",
        "val_path = \"/content/drive/MyDrive/Colab Notebooks/new dataset/val\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/new dataset/test\"\n",
        "\n",
        "# Define the classes\n",
        "classes = ['0', '1', '2', '3', '4']\n",
        "\n",
        "# Function to load images\n",
        "def load_images(dataset_path):\n",
        "    images = {}\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        images[class_name] = [cv2.imread(os.path.join(class_path, img)) for img in os.listdir(class_path)]\n",
        "    return images\n",
        "\n",
        "# Load the images\n",
        "train_images = load_images(train_path)\n",
        "test_images = load_images(test_path)\n",
        "val_images = load_images(val_path)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "sROP6K85XVgG",
        "outputId": "6a382ab2-2eeb-465e-b59c-ed518e91c4de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-51e729992f03>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mval_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-51e729992f03>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-51e729992f03>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get label distribution\n",
        "def get_label_distribution(dataset_path):\n",
        "    distribution = {}\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        distribution[class_name] = len(os.listdir(class_path))\n",
        "    return distribution\n",
        "\n",
        "# Get the label distribution for each dataset\n",
        "train_distribution = get_label_distribution(train_path)\n",
        "test_distribution = get_label_distribution(test_path)\n",
        "val_distribution = get_label_distribution(val_path)\n",
        "\n",
        "# Print the label distribution\n",
        "print(\"Training Set:\", train_distribution)\n",
        "print(\"Testing Set:\", test_distribution)\n",
        "print(\"Validation Set:\", val_distribution)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ahBakQWIXVgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot label distribution\n",
        "def plot_label_distribution(distribution, title):\n",
        "    plt.bar(distribution.keys(), distribution.values())\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the label distribution for each dataset\n",
        "plot_label_distribution(train_distribution, 'Training Set')\n",
        "plot_label_distribution(test_distribution, 'Testing Set')\n",
        "plot_label_distribution(val_distribution, 'Validation Set')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KvRf0O6pXVgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to visualize images\n",
        "def visualize_images(images, title):\n",
        "    num_samples_per_class = 3\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_images = images[class_name][:num_samples_per_class]\n",
        "        for j, img in enumerate(class_images):\n",
        "            plt.subplot(len(classes), num_samples_per_class, i * num_samples_per_class + j + 1)\n",
        "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert from BGR to RGB\n",
        "            plt.title(f\"{title} - Class {class_name}\")\n",
        "            plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "qadpSdyjXVgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the images\n",
        "visualize_images(train_images, 'Training Set')\n",
        "visualize_images(test_images, 'Testing Set')\n",
        "visualize_images(val_images, 'Validation Set')"
      ],
      "metadata": {
        "trusted": true,
        "id": "h0stXIdtXVgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocess_extract_images(path, classes, resize_dim=(98, 98), roi_coords=(13, 13, 78, 78)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    total_images = sum([len(os.listdir(os.path.join(path, class_name))) for class_name in classes])\n",
        "    processed_images = 0\n",
        "\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            # Load the image\n",
        "            img = cv2.imread(os.path.join(class_path, img_name))\n",
        "\n",
        "            # Resize the image\n",
        "            img = cv2.resize(img, resize_dim)\n",
        "\n",
        "            # Extract the ROI (Region of Interest)\n",
        "            x, y, w, h = roi_coords\n",
        "            img = img[y:y+h, x:x+w]\n",
        "\n",
        "            # Convert the image to float32 and normalize it\n",
        "            img = np.array(img, dtype='float32')\n",
        "            img = img / 127.5 - 1\n",
        "\n",
        "            # Add the image and label to the lists\n",
        "            images.append(img)\n",
        "            labels.append(i)\n",
        "\n",
        "            # Update and print progress\n",
        "            processed_images += 1\n",
        "            progress = (processed_images / total_images) * 100\n",
        "            print(f'Processing images: {progress:.2f}% completed', end='\\r')\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Load, preprocess, and extract features from the images\n",
        "X_train, Y_train = load_preprocess_extract_images(train_path, classes)\n",
        "X_val, Y_val = load_preprocess_extract_images(val_path, classes)\n",
        "X_test, Y_test = load_preprocess_extract_images(test_path, classes)"
      ],
      "metadata": {
        "trusted": true,
        "id": "x_r3uIz9XVgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to visualize images\n",
        "def visualize_images(images, labels, title):\n",
        "    num_samples_per_class = 3\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_indices = np.where(labels == i)[0][:num_samples_per_class]\n",
        "        for j, idx in enumerate(class_indices):\n",
        "            img = (images[i] + 1) * 127.5 / 255  # Convert back to 0-1 range for display\n",
        "            plt.subplot(len(classes), num_samples_per_class, i * num_samples_per_class + j + 1)\n",
        "            plt.imshow(img, cmap='gray')  # Use grayscale colormap for binary images\n",
        "            plt.title(f\"{title} - Class {class_name}\")\n",
        "            plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "visualize_images(X_train, Y_train, 'Training Set')\n",
        "visualize_images(X_val, Y_val, 'Validation Set')\n",
        "visualize_images(X_test, Y_test, 'Testing Set')"
      ],
      "metadata": {
        "trusted": true,
        "id": "GsGxeYz2XVgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of train : \",X_train.shape)\n",
        "print(\"shape of val : \",X_val.shape)\n",
        "print(\"shape of test : \",X_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Id81yS1MXVgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "\n",
        "# Define paths for augmented datasets\n",
        "aug_train_path = '/kaggle/working/augmented/train'\n",
        "aug_val_path = '/kaggle/working/augmented/val'\n",
        "\n",
        "# Function to create directories if they don't exist\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        for class_name in classes:\n",
        "            os.makedirs(os.path.join(path, class_name))\n",
        "\n",
        "# Create directories for augmented datasets\n",
        "create_dir(aug_train_path)\n",
        "create_dir(aug_val_path)\n",
        "\n",
        "# Initialize the ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Function to augment images\n",
        "def augment_images(source_path, target_path, target_count):\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(source_path, class_name)\n",
        "        target_class_path = os.path.join(target_path, class_name)\n",
        "\n",
        "        images = [cv2.imread(os.path.join(class_path, img)) for img in os.listdir(class_path)]\n",
        "        images = np.array(images)\n",
        "\n",
        "        # Data augmentation\n",
        "        aug_gen = datagen.flow(images, batch_size=1, save_to_dir=target_class_path,\n",
        "                               save_prefix='aug', save_format='jpeg')\n",
        "\n",
        "        # Generate enough images to reach the target count\n",
        "        current_count = len(os.listdir(target_class_path))\n",
        "        while current_count < target_count:\n",
        "            next(aug_gen)\n",
        "            current_count += 1\n",
        "\n",
        "# Calculate target count based on the majority class\n",
        "majority_class_count = max(train_distribution.values())\n",
        "\n",
        "# Augment the training and validation sets\n",
        "augment_images(train_path, aug_train_path, majority_class_count)\n",
        "augment_images(val_path, aug_val_path, majority_class_count)\n",
        "\n",
        "# Load the augmented images\n",
        "aug_train_images = load_images(aug_train_path)\n",
        "aug_val_images = load_images(aug_val_path)\n",
        "\n",
        "# Get the label distribution for the augmented datasets\n",
        "aug_train_distribution = get_label_distribution(aug_train_path)\n",
        "aug_val_distribution = get_label_distribution(aug_val_path)\n",
        "\n",
        "# Print the label distribution for augmented datasets\n",
        "print(\"Augmented Training Set:\", aug_train_distribution)\n",
        "print(\"Augmented Validation Set:\", aug_val_distribution)\n",
        "\n",
        "# Now you can use the augmented datasets for training\n",
        "train_path_aug = aug_train_path\n",
        "val_path_aug = aug_val_path"
      ],
      "metadata": {
        "trusted": true,
        "id": "miQ4s_BrXVgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load, preprocess, and extract features from the images\n",
        "X_train, Y_train = load_preprocess_extract_images(train_path_aug, classes)\n",
        "X_val, Y_val = load_preprocess_extract_images(val_path_aug, classes)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rELKsc30XVgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to visualize images\n",
        "def visualize_images(images, labels, title):\n",
        "    num_samples_per_class = 3\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_indices = np.where(labels == i)[0][:num_samples_per_class]\n",
        "        for j, idx in enumerate(class_indices):\n",
        "            img = (images[i] + 1) * 127.5 / 255  # Convert back to 0-1 range for display\n",
        "            plt.subplot(len(classes), num_samples_per_class, i * num_samples_per_class + j + 1)\n",
        "            plt.imshow(img, cmap='gray')  # Use grayscale colormap for binary images\n",
        "            plt.title(f\"{title} - Class {class_name}\")\n",
        "            plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Visualize the images\n",
        "visualize_images(X_train, Y_train, 'Training Set')\n",
        "visualize_images(X_val, Y_val, 'Validation Set')"
      ],
      "metadata": {
        "trusted": true,
        "id": "7a9w3aKlXVgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Conv2d\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(78, 78, 3)))\n",
        "\n",
        "# Maxpooling2d\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Batch Normalization\n",
        "model.add(BatchNormalization())\n",
        "#_____________________________________________________________________\n",
        "# Conv2d_1\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "\n",
        "# Maxpooling2d_1\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Batch Normalization_1\n",
        "model.add(BatchNormalization())\n",
        "#_____________________________________________________________________\n",
        "\n",
        "# Conv2d_2\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "\n",
        "# Dropout_2\n",
        "model.add(Dropout(0.25))  # Assuming a dropout rate of 0.25\n",
        "\n",
        "# Maxpooling2d_2\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Batch Normalization_2\n",
        "model.add(BatchNormalization())\n",
        "#_____________________________________________________________________\n",
        "\n",
        "# Conv2d_3\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "\n",
        "# Dropout_1\n",
        "model.add(Dropout(0.25))  # Assuming a dropout rate of 0.25\n",
        "\n",
        "# Maxpooling2d_3\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Batch Normalization_3\n",
        "model.add(BatchNormalization())\n",
        "#_____________________________________________________________________\n",
        "\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense\n",
        "model.add(Dense(units=8, activation='relu')) # Assuming 128 units\n",
        "\n",
        "# Dropout_2\n",
        "model.add(Dropout(0.5)) # Assuming a dropout rate of 0.5\n",
        "\n",
        "# Dense_1\n",
        "model.add(Dense(units=5, activation='softmax')) # Assuming 5 output classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "9FD0sXjBXVgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the model with L2 regularization\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001), input_shape=(78, 78, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "GFTmQmUNXVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "# Compile the model with a specified initial learning rate\n",
        "initial_learning_rate = 0.0001\n",
        "# Compile the model with Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.03))  # Adjusted decay rate\n",
        "\n",
        "# Callback for the learning rate scheduler\n",
        "lr_scheduler = LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-FUopbAKXVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BWy0S65yXVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train,Y_train, epochs=100, batch_size=32 ,validation_data=(X_val, Y_val),callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "trusted": true,
        "id": "1dheuk7CXVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predict probabilities for test set\n",
        "Y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "Y_pred = np.argmax(Y_pred_probs, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1yn7Qzr8XVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "# Define class labels\n",
        "\n",
        "class_labels = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4']\n",
        "\n",
        "# Plot confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Gc2R8Cp5XVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "gBJiLdGFXVgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "8iiixrPjXVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "class_report = classification_report(Y_test, Y_pred, target_names=classes)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IaeBujwWXVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot actual vs predicted labels\n",
        "def plot_actual_vs_predicted(actual, predicted, class_labels):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(len(class_labels)):\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.hist([actual, predicted], bins=np.arange(len(class_labels) + 1) - 0.5, color=['blue', 'orange'], edgecolor='black', alpha=0.7, label=['Actual', 'Predicted'])\n",
        "        plt.xticks(range(len(class_labels)), class_labels)\n",
        "        plt.xlabel('Class')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title(f'Class {i}')\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot actual vs predicted labels\n",
        "plot_actual_vs_predicted(Y_test, Y_pred, class_labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Fv_D-KnZXVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define a function to visualize images along with their actual and predicted labels\n",
        "def visualize_actual_vs_predicted(images, actual_labels, predicted_labels, class_labels, num_samples=5):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i in range(num_samples):\n",
        "        idx = random.randint(0, len(images)-1)\n",
        "        plt.subplot(2, num_samples, i + 1)\n",
        "        plt.imshow(images[idx], cmap='gray')\n",
        "        plt.title(f'Actual: {class_labels[actual_labels[idx]]}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, num_samples, num_samples + i + 1)\n",
        "        plt.imshow(images[idx], cmap='gray')\n",
        "        plt.title(f'Predicted: {class_labels[predicted_labels[idx]]}')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize actual vs predicted labels along with images\n",
        "visualize_actual_vs_predicted(X_test, Y_test, Y_pred, class_labels)"
      ],
      "metadata": {
        "id": "IyOh8AR6XVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(hp):\n",
        "    model1 = Sequential([\n",
        "        model,\n",
        "        Flatten(),\n",
        "        Dense(hp.Int('units', min_value=128, max_value=512, step=32), activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        Dropout(hp.Float('dropout', min_value=0.3, max_value=0.7, step=0.1)),\n",
        "        Dense(5, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])),\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "9MlUf-HxXVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to preprocess and predict a single image\n",
        "def predict_image(image_path, model, class_labels):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
        "\n",
        "    # Resize the image to the required size (78, 78)\n",
        "    img_resized = cv2.resize(img, (78, 78))\n",
        "\n",
        "    # Extract the ROI (Region of Interest)\n",
        "    x, y, w, h = 13, 13, 78, 78\n",
        "    img_roi = img_resized[y:y+h, x:x+w]\n",
        "\n",
        "    # Normalize the image\n",
        "    img_normalized = np.array(img_roi, dtype='float32') / 127.5 - 1\n",
        "\n",
        "    # Expand dimensions to match the input shape of the model (1, 78, 78, 3)\n",
        "    img_expanded = np.expand_dims(img_normalized, axis=0)\n",
        "\n",
        "    # Predict the class\n",
        "    prediction = model.predict(img_expanded)\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Display the image with the predicted class\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Class: {class_labels[predicted_class]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/drive/MyDrive/Colab Notebooks/new dataset/test/0/9003175L.png\"\n",
        "predict_image(image_path, model, class_labels)\n"
      ],
      "metadata": {
        "id": "4DTVqvfmwdEu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}